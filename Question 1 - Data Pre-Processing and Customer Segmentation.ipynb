{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the project workspace.\n",
    "import os\n",
    "print(\"Project Workspace:\", os.getcwd())\n",
    "print()\n",
    "\n",
    "# Import all necessary packages for the project.\n",
    "import pandas as pan\n",
    "import statistics as myStats\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.cluster import DBSCAN as sklearnDBSCAN\n",
    "import seaborn as sb\n",
    "import glob\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Revome scientific notation to expand numbers in the dataset up to the\n",
    "# second decimal place.\n",
    "pan.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the \"Sale Date\" data, we get the day, month and date columns for each transaction.\n",
    "def fetchMonthAndYearColumns(dataFile):\n",
    "    dataFile[\"Day\"] = dataFile[\"Sale_Date\"].apply(lambda month: month.split(\"-\")[2])\n",
    "    dataFile[\"Month\"] = dataFile[\"Sale_Date\"].apply(lambda month: month.split(\"-\")[1])\n",
    "    dataFile[\"Year\"] = dataFile[\"Sale_Date\"].apply(lambda year: year.split(\"-\")[0])\n",
    "    dataFile.drop(columns = [\"Sale_Date\"])\n",
    "    return dataFile\n",
    "\n",
    "# Aggregate the data for each month by \"UniSA Customer Number\" and \"Month of Sale\"\n",
    "# to get \"No of Trips per day\", \"No of Purchases\" and the \"Total Sale Amount Inclusive of GST\".\n",
    "def aggregateYearData(dataFile):\n",
    "    # Drop all rows with \"NA\" for \"UniSA Customer Number\".\n",
    "    dataFile = dataFile.dropna(subset = [\"UniSA_Customer_No\"])\n",
    "    # Ensure that the minimum value for \"Quantity Sold\" is \"1\".\n",
    "    dataFile[\"Quantity_Sold\"][dataFile[\"Quantity_Sold\"] < 1.0] = 1\n",
    "    # First aggregate over a day.\n",
    "    dataFile = dataFile.groupby(by = [\"Day\", \"Month\", \"Year\", \"UniSA_Receipt_No1\", \"UniSA_Customer_No\"], as_index = False).agg({\"Total_Sale_Amount_InclusiveGST\": \"mean\", \"Quantity_Sold\": \"sum\"})\n",
    "    dataFile = dataFile.groupby(by = [\"Day\", \"Month\", \"Year\", \"UniSA_Customer_No\"], as_index = False).agg({\"UniSA_Receipt_No1\": \"count\", \"Total_Sale_Amount_InclusiveGST\": \"sum\", \"Quantity_Sold\": \"sum\"}).rename(columns = {\"UniSA_Receipt_No1\": \"No_of_Trips\", \"Total_Sale_Amount_InclusiveGST\": \"Total_Sale_Amount\"})\n",
    "    print(\"Size of Dataset:\", dataFile.shape)\n",
    "    # Then aggregate over a month.\n",
    "    dataFile = dataFile.groupby(by = [\"Month\", \"Year\", \"UniSA_Customer_No\"], as_index = False).agg({\"No_of_Trips\": \"sum\", \"Total_Sale_Amount\": \"sum\", \"Quantity_Sold\": \"sum\"}).rename(columns = {\"No_of_Trips\": \"Monthly_Total_Trips\", \"Quantity_Sold\": \"Total_Quantity_Sold\"})\n",
    "    print(\"Size of Dataset:\", dataFile.shape)\n",
    "    dataFile = dataFile[(dataFile[\"Monthly_Total_Trips\"] >= 4) & (dataFile[\"Monthly_Total_Trips\"] <= 31)]\n",
    "    # And finally aggregate over a year\n",
    "    dataFile = dataFile.groupby(by = [\"Year\", \"UniSA_Customer_No\"], as_index = False).agg({\"Monthly_Total_Trips\": \"mean\", \"Total_Sale_Amount\": \"mean\", \"Total_Quantity_Sold\": \"mean\"}).rename(columns = {\"Monthly_Total_Trips\": \"Average_Monthly_Trips\", \"Total_Sale_Amount\": \"Average_Sale_Amount\", \"Total_Quantity_Sold\": \"Average_Quantity_Sold\"})\n",
    "    dataFile[\"Average_Monthly_Trips\"] = dataFile[\"Average_Monthly_Trips\"].round()    \n",
    "    dataFile[\"Average_Quantity_Sold\"] = dataFile[\"Average_Quantity_Sold\"].round()\n",
    "    print(\"Size of Dataset:\", dataFile.shape)\n",
    "    return dataFile\n",
    "\n",
    "# Aggregate the data for each month by \"UniSA Customer Number\" and \"Month of Sale\"\n",
    "# to get \"No of Trips per day\", \"No of Purchases\" and the \"Total Sale Amount Inclusive of GST\".\n",
    "def aggregateMonthData(dataFile):\n",
    "    # Drop all rows with \"NA\" for \"UniSA Customer Number\".\n",
    "    dataFile = dataFile.dropna(subset = [\"UniSA_Customer_No\"])\n",
    "    # Ensure that the minimum value for \"Quantity Sold\" is \"1\".\n",
    "    dataFile[\"Quantity_Sold\"][dataFile[\"Quantity_Sold\"] < 1.0] = 1\n",
    "    # First aggregate over a day.\n",
    "    dataFile = dataFile.groupby(by = [\"Day\", \"Month\", \"Year\", \"UniSA_Receipt_No1\", \"UniSA_Customer_No\"], as_index = False).agg({\"Total_Sale_Amount_InclusiveGST\": \"mean\", \"Quantity_Sold\": \"sum\"})\n",
    "    dataFile = dataFile.groupby(by = [\"Day\", \"Month\", \"Year\", \"UniSA_Customer_No\"], as_index = False).agg({\"UniSA_Receipt_No1\": \"count\", \"Total_Sale_Amount_InclusiveGST\": \"sum\", \"Quantity_Sold\": \"sum\"}).rename(columns = {\"UniSA_Receipt_No1\": \"No_of_Trips\", \"Total_Sale_Amount_InclusiveGST\": \"Total_Sale_Amount\"})\n",
    "    # Eliminate all those customers who made more than 7 trips in a day.\n",
    "    dataFile = dataFile[dataFile['No_of_Trips'] < 6]\n",
    "    # Then aggregate over a month.\n",
    "    dataFile = dataFile.groupby(by = [\"Month\", \"Year\", \"UniSA_Customer_No\"], as_index = False).agg({\"No_of_Trips\": \"mean\", \"Total_Sale_Amount\": \"mean\", \"Quantity_Sold\": \"mean\"}).rename(columns = {\"No_of_Trips\": \"Daily_Average_Trips\", \"Total_Sale_Amount\": \"Average_Sale_Amount\", \"Quantity_Sold\": \"Average_Quantity_Sold\"})\n",
    "    dataFile[\"Daily_Average_Trips\"] = dataFile[\"Daily_Average_Trips\"].round()    \n",
    "    dataFile[\"Average_Quantity_Sold\"] = dataFile[\"Average_Quantity_Sold\"].round()\n",
    "    return dataFile\n",
    "\n",
    "# Import data for each day and collate the data. For this, we create a function\n",
    "# \"importAndCollate()\".\n",
    "def importAndCollate():\n",
    "    dataFileList = []\n",
    "    fileNames = [fileName for fileName in glob.glob(\"<insert_year>/*.csv\", recursive = True)]\n",
    "    for fileName in fileNames:\n",
    "        dataFileList.append(pan.read_csv(fileName))\n",
    "    yearDataFile = pan.concat(dataFileList, ignore_index = False)\n",
    "    print(\"Size of Dataset:\", yearDataFile.shape)\n",
    "    return yearDataFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all data for a year and collate it in one dataframe.\n",
    "yearDataFile = importAndCollate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the \"Sale Date\" column into three different columns, one each\n",
    "# for \"Sale Day\", \"Sale Month\" and \"Sale Year\"\n",
    "yearDataFile = fetchMonthAndYearColumns(yearDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data over each month to get \"Number of Trips in a Month\",\n",
    "# \"Average Sale Amount\" and \"Quantity Sold\" to each loyal \"UniSA Customer Number\".\n",
    "aggregatedMonthlyData = aggregateMonthData(yearDataFile)\n",
    "aggregatedMonthlyData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the different customer segments for a single day\n",
    "# using different clustering techniques. For starters, we consider\n",
    "# only data for one month's data. In this case January (Month == \"01\").\n",
    "# Each\"UniSA Customer Number\" is a point in three dimensions: \"Average Number of Trips made Daily\"\n",
    "# \"Average Sale Amount\", and \"Average Quantity Sold\".\n",
    "\n",
    "# Before we proceed, let's plot our data to get an idea of the different\n",
    "# customer segements that may exist. Our data is three dimensional, but\n",
    "# we need to plot it in two dimensions. For this we'll use Principal\n",
    "# Component Analysis. Before that we normalize our data.\n",
    "aggregatedJanuaryData = aggregatedMonthlyData[aggregatedMonthlyData[\"Month\"] == \"01\"]\n",
    "aggregatedJanuaryDataForPCA = aggregatedJanuaryData[['Daily_Average_Trips', 'Average_Sale_Amount', 'Average_Quantity_Sold']]\n",
    "aggregatedJanuaryDataForPCA['Daily_Average_Trips'] = (aggregatedJanuaryDataForPCA['Daily_Average_Trips'] - myStats.mean(aggregatedJanuaryDataForPCA['Daily_Average_Trips'])) / myStats.stdev(aggregatedJanuaryDataForPCA['Daily_Average_Trips'])\n",
    "aggregatedJanuaryDataForPCA['Average_Sale_Amount'] = (aggregatedJanuaryDataForPCA['Average_Sale_Amount'] - myStats.mean(aggregatedJanuaryDataForPCA['Average_Sale_Amount'])) / myStats.stdev(aggregatedJanuaryDataForPCA['Average_Sale_Amount'])\n",
    "aggregatedJanuaryDataForPCA['Average_Quantity_Sold'] = (aggregatedJanuaryDataForPCA['Average_Quantity_Sold'] - myStats.mean(aggregatedJanuaryDataForPCA['Average_Quantity_Sold'])) / myStats.stdev(aggregatedJanuaryDataForPCA['Average_Quantity_Sold'])\n",
    "aggregatedJanuaryData.index = range(0, len(aggregatedJanuaryData.index.tolist()))\n",
    "aggregatedJanuaryDataForPCA.index = range(0, len(aggregatedJanuaryDataForPCA.index.tolist()))\n",
    "\n",
    "# We create an object for Principal Component Analysis (PCA)\n",
    "pCA = sklearnPCA(n_components = 2)\n",
    "pCAJanuaryData = pan.DataFrame(pCA.fit_transform(aggregatedJanuaryDataForPCA))\n",
    "sb.scatterplot(x = pCAJanuaryData[0], y = pCAJanuaryData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PCA scatterplot for shows distinct groups of straight lines, of\n",
    "# which one group might be outliers. To deal with such data, we use the\n",
    "# DBSCAN Clustering method for customer segmentation.\n",
    "dbscanClustering = sklearnDBSCAN(eps = 3, min_samples = 10).fit(aggregatedJanuaryDataForPCA)\n",
    "clusterNumbers = [cluster + 1 for cluster in dbscanClustering.labels_.tolist()]\n",
    "aggregatedJanuaryDataForPCA[\"Cluster\"] = clusterNumbers\n",
    "pCAJanuaryData.columns = [\"0\", \"1\"]\n",
    "pCAJanuaryData[\"Cluster\"] = clusterNumbers\n",
    "aggregatedJanuaryData[\"Cluster\"] = clusterNumbers\n",
    "scatterPlot = sb.scatterplot(x = pCAJanuaryData[\"0\"], y = pCAJanuaryData[\"1\"], hue = pCAJanuaryData[\"Cluster\"], data = pCAJanuaryData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the results of the DBSCAN Clustering for the month of January,\n",
    "# we see that there are 4 clusters, from which one cluster is simply\n",
    "# outliers in the data. We remove these outliers for further analysis.\n",
    "outlierRecordIndices = pCAJanuaryData[pCAJanuaryData[\"Cluster\"] == 0].index.tolist()\n",
    "pCAJanuaryData = pCAJanuaryData.drop(outlierRecordIndices, axis = 0)\n",
    "aggregatedJanuaryDataForPCA = aggregatedJanuaryDataForPCA.drop(outlierRecordIndices, axis = 0)\n",
    "aggregatedJanuaryData = aggregatedJanuaryData.drop(outlierRecordIndices, axis = 0)\n",
    "print(\"Number of records for PCA plot of January Data:\", len(aggregatedJanuaryDataForPCA.index))\n",
    "print(\"Number of records for January Data:\", len(aggregatedJanuaryData.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our three clusters, let's check the distributions of the\n",
    "# following variables in each of these clusters: \"Average Number of Trips\n",
    "# made per day\", \"Average Sale Amount for the month\" and \"Average Quantity\n",
    "# Sold to the Customer\".\n",
    "\n",
    "# Let's create box plots for \"Average Number of Trips made in the month\".\n",
    "plt.figure()\n",
    "boxPlotAverageNoOfTripsJanuary = sb.boxplot(x = \"Cluster\", y = \"Daily_Average_Trips\", data = aggregatedJanuaryData)\n",
    "boxPlotAverageNoOfTripsJanuary.set(xlabel = \"Segment No.\", ylabel = \"Average No. of Trips per Day\")\n",
    "\n",
    "# Let's create box plots for \"Average Sale Amount\".\n",
    "plt.figure()\n",
    "boxPlotAverageSaleAmountJanuary = sb.boxplot(x = \"Cluster\", y = \"Average_Sale_Amount\", data = aggregatedJanuaryData)\n",
    "boxPlotAverageSaleAmountJanuary.set(xlabel = \"Segment No.\", ylabel = \"Average Spending per Day\")\n",
    "\n",
    "# Let's create box plots for \"Average Quantity Sold to the Customer\".\n",
    "plt.figure()\n",
    "boxPlotAverageQuantitySoldJanuary = sb.boxplot(x = \"Cluster\", y = \"Average_Quantity_Sold\", data = aggregatedJanuaryData)\n",
    "boxPlotAverageQuantitySoldJanuary.set(xlabel = \"Segment No.\", ylabel = \"Average No. of Products Purchased per Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data over each month to get \"Number of Trips in a Month\",\n",
    "# \"Average Sale Amount\" and \"Quantity Sold\" to each loyal \"UniSA Customer Number\".\n",
    "aggregatedYearlyData = aggregateYearData(yearDataFile)\n",
    "aggregatedYearlyData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the different customer segments for the entire year\n",
    "# using different clustering techniques. Each \"UniSA Customer Number\"\n",
    "# is a point in three dimensions: \"Average Number of Trips made in a Month\"\n",
    "# \"Average Sale Amount\", and \"Average Quantity Sold\".\n",
    "\n",
    "# Before we proceed, let's plot our data to get an idea of the different\n",
    "# customer segements that may exist. Our data is three dimensional, but\n",
    "# we need to plot it in two dimensions. For this we'll use Principal\n",
    "# Component Analysis. Before that we normalize our data.\n",
    "aggregatedYearlyDataForPCA = aggregatedYearlyData[[\"Average_Monthly_Trips\", \"Average_Sale_Amount\", \"Average_Quantity_Sold\"]]\n",
    "aggregatedYearlyDataForPCA[\"Average_Monthly_Trips\"] = (aggregatedYearlyDataForPCA[\"Average_Monthly_Trips\"] - myStats.mean(aggregatedYearlyDataForPCA[\"Average_Monthly_Trips\"])) / myStats.stdev(aggregatedYearlyDataForPCA[\"Average_Monthly_Trips\"])\n",
    "aggregatedYearlyDataForPCA[\"Average_Sale_Amount\"] = (aggregatedYearlyDataForPCA[\"Average_Sale_Amount\"] - myStats.mean(aggregatedYearlyDataForPCA[\"Average_Sale_Amount\"])) / myStats.stdev(aggregatedYearlyDataForPCA[\"Average_Sale_Amount\"])\n",
    "aggregatedYearlyDataForPCA[\"Average_Quantity_Sold\"] = (aggregatedYearlyDataForPCA[\"Average_Quantity_Sold\"] - myStats.mean(aggregatedYearlyDataForPCA[\"Average_Quantity_Sold\"])) / myStats.stdev(aggregatedYearlyDataForPCA[\"Average_Quantity_Sold\"])\n",
    "\n",
    "# We create an object for Principal Component Analysis (PCA)\n",
    "pCA = sklearnPCA(n_components = 2)\n",
    "pCAYearData = pan.DataFrame(pCA.fit_transform(aggregatedYearlyDataForPCA))\n",
    "pCAYearData.columns = [\"0\", \"1\"]\n",
    "pCAYearData.index = aggregatedYearlyData[\"UniSA_Customer_No\"]\n",
    "aggregatedYearlyDataForPCA.index = aggregatedYearlyData[\"UniSA_Customer_No\"]\n",
    "aggregatedYearlyData.index = aggregatedYearlyData[\"UniSA_Customer_No\"]\n",
    "sb.scatterplot(x = pCAYearData[\"0\"], y = pCAYearData[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PCA scatterplot for shows distinct groups of straight lines, of\n",
    "# which one group might be outliers. To deal with such data, we use the\n",
    "# DBSCAN Clustering method for customer segmentation.\n",
    "dbscanClustering = sklearnDBSCAN(eps = 3, min_samples = 10).fit(aggregatedYearlyDataForPCA)\n",
    "clusterNumbers = [cluster + 1 for cluster in dbscanClustering.labels_.tolist()]\n",
    "aggregatedYearlyDataForPCA[\"Cluster\"] = clusterNumbers\n",
    "pCAYearData.columns = [\"0\", \"1\"]\n",
    "pCAYearData[\"Cluster\"] = clusterNumbers\n",
    "aggregatedYearlyData[\"Cluster\"] = clusterNumbers\n",
    "scatterPlot = sb.scatterplot(x = pCAYearData[\"0\"], y = pCAYearData[\"1\"], hue = pCAYearData[\"Cluster\"], data = pCAYearData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is evident that there is one outlier which will cause problems while\n",
    "# clustering our data. For this reason, we remove the outlier belonging to\n",
    "# cluster \"0\".\n",
    "outlierRecordIndices = pCAYearData[pCAYearData[\"Cluster\"] == 0].index.tolist()\n",
    "outlierRecordIndices\n",
    "pCAYearData = pCAYearData.drop(outlierRecordIndices, axis = 0)\n",
    "aggregatedYearlyDataForPCA = aggregatedYearlyDataForPCA.drop(outlierRecordIndices, axis = 0)\n",
    "aggregatedYearlyData = aggregatedYearlyData.drop(outlierRecordIndices, axis = 0)\n",
    "scatterPlot = sb.scatterplot(x = pCAYearData[\"0\"], y = pCAYearData[\"1\"], hue = pCAYearData[\"Cluster\"], data = pCAYearData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that there are no distinct groups in the data. Let's\n",
    "# try using Herarchical Clustering methods.\n",
    "linked = linkage(pCAYearData, method = \"ward\")\n",
    "\n",
    "labelList = pCAYearData.index.tolist()\n",
    "\n",
    "plt.figure(figsize = (10, 8))  \n",
    "heirarchicalClustering = dendrogram(linked, orientation = \"left\", labels = labelList, distance_sort = \"descending\", show_leaf_counts = True, color_threshold = 55)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that there are three possible segments of customers for the year.\n",
    "# We need to extract the segment numbers for each segment.\n",
    "heirarchicalClustering = fcluster(linked, t = 55, depth = 4, criterion = \"distance\")\n",
    "\n",
    "# Next, we add these segment details to our aggregated data.\n",
    "aggregatedYearlyData[\"Segment_No\"] = heirarchicalClustering\n",
    "\n",
    "# Let's check the distribution of \"UniSA Customer Numbers\" based on \"Average Number\n",
    "# of Trips made per Month\", \"Average Sale Amount for the Month\" and \"Average Quantity\n",
    "# Sold.\"\n",
    "\n",
    "# Let's create box plots for \"Average Number of Trips made in the month\".\n",
    "plt.figure()\n",
    "boxPlotAverageNoOfTrips = sb.boxplot(x = \"Segment_No\", y = \"Average_Monthly_Trips\", data = aggregatedYearlyData)\n",
    "boxPlotAverageNoOfTrips.set(xlabel = \"Segment No.\", ylabel = \"Average No. of Trips per Month\")\n",
    "\n",
    "# Let's create box plots for \"Average Sale Amount\".\n",
    "plt.figure()\n",
    "boxPlotAverageSaleAmount = sb.boxplot(x = \"Segment_No\", y = \"Average_Sale_Amount\", data = aggregatedYearlyData)\n",
    "boxPlotAverageSaleAmount.set(xlabel = \"Segment No.\", ylabel = \"Average Spending per Month\")\n",
    "\n",
    "# Let's create box plots for \"Average Quantity Sold to the Customer\".\n",
    "plt.figure()\n",
    "boxPlotAverageQuantitySold = sb.boxplot(x = \"Segment_No\", y = \"Average_Quantity_Sold\", data = aggregatedYearlyData)\n",
    "boxPlotAverageQuantitySold.set(xlabel = \"Segment No.\", ylabel = \"Average No. of Products Purchased per Month\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
